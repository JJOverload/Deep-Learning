Quadruple image set, with proper rotations this time, which will also go through augmentation.

added batch normalization, and then another batch normalization after pooling, which yielded interesting graphs.
batch_size = 64
epoch 30


-----------------------

def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    

    # Entry block
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(64, (3, 3), strides=1, activation='relu')(x)
    x = layers.AveragePooling2D((2, 2))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)
    
    
    
    #x = layers.AveragePooling2D((2, 2))(x)
    #x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)


    if num_classes == 2:
        units = 1
    else:
        units = num_classes

    x = layers.Flatten()(x)
    x = layers.Dropout(0.25)(x)
    # We specify activation=None so as to return logits
    outputs = layers.Dense(units, activation=None)(x)
    return keras.Model(inputs, outputs)

print("Building a model.")
model = make_model(input_shape=image_size+(3,), num_classes=3)

--------------------------------------------------------

2024-01-24 20:24:55.178375: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-24 20:24:55.197666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Finished importing.
Filter out corrupted images.
Deleted 0 images
Generating a Dataset.
Found 5090 files belonging to 3 classes.
Using 4072 files for training.
Using 1018 files for validation.
Applying `data_augmentation` to the training images.
Prefetching samples in GPU memory helps maximize GPU utilization.
Building a model.
Saved Model Layout Map.
Training the model.
Epoch 1/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.4983 - loss: 12.3307 - val_accuracy: 0.4980 - val_loss: 1.0972
Epoch 2/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.6710 - loss: 1.4460 - val_accuracy: 0.5383 - val_loss: 0.9700
Epoch 3/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.7193 - loss: 0.9621 - val_accuracy: 0.7073 - val_loss: 0.7020
Epoch 4/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.7724 - loss: 0.6644 - val_accuracy: 0.7682 - val_loss: 0.5491
Epoch 5/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.8369 - loss: 0.4598 - val_accuracy: 0.7790 - val_loss: 0.5840
Epoch 6/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.8213 - loss: 0.5915 - val_accuracy: 0.6739 - val_loss: 0.9673
Epoch 7/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.8130 - loss: 0.6277 - val_accuracy: 0.8772 - val_loss: 0.3323
Epoch 8/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.8803 - loss: 0.3909 - val_accuracy: 0.8173 - val_loss: 0.5971
Epoch 9/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.8922 - loss: 0.3390 - val_accuracy: 0.8497 - val_loss: 0.4285
Epoch 10/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.8941 - loss: 0.3303 - val_accuracy: 0.7426 - val_loss: 0.8514
Epoch 11/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.8602 - loss: 0.4262 - val_accuracy: 0.8831 - val_loss: 0.4231
Epoch 12/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9025 - loss: 0.3068 - val_accuracy: 0.9194 - val_loss: 0.2979
Epoch 13/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.9251 - loss: 0.2386 - val_accuracy: 0.9145 - val_loss: 0.3115
Epoch 14/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.8861 - loss: 0.3796 - val_accuracy: 0.9136 - val_loss: 0.3758
Epoch 15/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9188 - loss: 0.2507 - val_accuracy: 0.9617 - val_loss: 0.1631
Epoch 16/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9347 - loss: 0.2236 - val_accuracy: 0.9194 - val_loss: 0.2698
Epoch 17/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9250 - loss: 0.2538 - val_accuracy: 0.8674 - val_loss: 0.5098
Epoch 18/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9355 - loss: 0.2345 - val_accuracy: 0.9263 - val_loss: 0.3193
Epoch 19/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9259 - loss: 0.2293 - val_accuracy: 0.9126 - val_loss: 0.3409
Epoch 20/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9508 - loss: 0.1622 - val_accuracy: 0.9509 - val_loss: 0.2370
Epoch 21/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9540 - loss: 0.1322 - val_accuracy: 0.8802 - val_loss: 0.4839
Epoch 22/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9545 - loss: 0.1675 - val_accuracy: 0.9420 - val_loss: 0.2506
Epoch 23/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9329 - loss: 0.2339 - val_accuracy: 0.9401 - val_loss: 0.3048
Epoch 24/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9408 - loss: 0.2024 - val_accuracy: 0.9695 - val_loss: 0.2092
Epoch 25/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9560 - loss: 0.1546 - val_accuracy: 0.9037 - val_loss: 0.4400
Epoch 26/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9662 - loss: 0.1406 - val_accuracy: 0.9745 - val_loss: 0.1951
Epoch 27/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.9670 - loss: 0.1338 - val_accuracy: 0.9686 - val_loss: 0.1896
Epoch 28/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 69s 1s/step - accuracy: 0.9549 - loss: 0.1911 - val_accuracy: 0.9381 - val_loss: 0.3088
Epoch 29/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9391 - loss: 0.2103 - val_accuracy: 0.8959 - val_loss: 0.3549
Epoch 30/30
64/64 ━━━━━━━━━━━━━━━━━━━━ 68s 1s/step - accuracy: 0.9161 - loss: 0.3569 - val_accuracy: 0.8959 - val_loss: 0.5034
Saving model.
Plotting Model Accuracy.
Saved Graph #1
Plotting Model Loss
Saved Graph #2.
Loading model.
Running inference on new data.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step
[[ 8.514601   9.744721  -2.5347111]]
indexOfMax: 1
Done


