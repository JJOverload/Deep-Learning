Quadruple image set, with proper rotations this time, which will also go through augmentation.

1x batch normalization, and then another 1x batch normalization after pooling.
batch_size = 64
epoch decreased to 25
reduced dimension

-----------------------

def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    

    # Entry block
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(32, (3, 3), strides=1, activation='relu')(x)
    x = layers.AveragePooling2D((2, 2))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(64, (3, 3), strides=1, activation='relu')(x)
    
    
    
    #x = layers.AveragePooling2D((2, 2))(x)
    #x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)


    if num_classes == 2:
        units = 1
    else:
        units = num_classes

    x = layers.Flatten()(x)
    x = layers.Dropout(0.25)(x)
    # We specify activation=None so as to return logits
    outputs = layers.Dense(units, activation=None)(x)
    return keras.Model(inputs, outputs)

print("Building a model.")
model = make_model(input_shape=image_size+(3,), num_classes=3)

--------------------------------------------------------

2024-01-25 04:49:29.976081: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-25 04:49:29.995169: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Finished importing.
Filter out corrupted images.
Deleted 0 images
Generating a Dataset.
Found 5090 files belonging to 3 classes.
Using 4072 files for training.
Using 1018 files for validation.
Applying `data_augmentation` to the training images.
Prefetching samples in GPU memory helps maximize GPU utilization.
Building a model.
Saved Model Layout Map.
Training the model.
Epoch 1/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 439ms/step - accuracy: 0.4323 - loss: 3.4754 - val_accuracy: 0.4912 - val_loss: 1.0198
Epoch 2/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 449ms/step - accuracy: 0.6367 - loss: 0.7951 - val_accuracy: 0.5403 - val_loss: 0.9465
Epoch 3/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 456ms/step - accuracy: 0.6927 - loss: 0.7017 - val_accuracy: 0.6189 - val_loss: 0.8689
Epoch 4/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 454ms/step - accuracy: 0.7235 - loss: 0.6939 - val_accuracy: 0.6788 - val_loss: 0.7524
Epoch 5/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 456ms/step - accuracy: 0.7806 - loss: 0.5383 - val_accuracy: 0.6935 - val_loss: 0.7242
Epoch 6/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 459ms/step - accuracy: 0.8023 - loss: 0.4932 - val_accuracy: 0.7957 - val_loss: 0.5424
Epoch 7/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 458ms/step - accuracy: 0.8478 - loss: 0.4387 - val_accuracy: 0.7682 - val_loss: 0.6011
Epoch 8/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 456ms/step - accuracy: 0.8163 - loss: 0.4792 - val_accuracy: 0.8026 - val_loss: 0.5100
Epoch 9/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.8469 - loss: 0.3876 - val_accuracy: 0.8654 - val_loss: 0.3641
Epoch 10/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.8486 - loss: 0.4415 - val_accuracy: 0.7750 - val_loss: 0.7246
Epoch 11/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 454ms/step - accuracy: 0.8333 - loss: 0.4505 - val_accuracy: 0.8929 - val_loss: 0.3757
Epoch 12/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.8827 - loss: 0.3120 - val_accuracy: 0.8340 - val_loss: 0.4493
Epoch 13/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.9142 - loss: 0.2565 - val_accuracy: 0.9096 - val_loss: 0.3156
Epoch 14/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 456ms/step - accuracy: 0.8785 - loss: 0.3404 - val_accuracy: 0.8448 - val_loss: 0.4314
Epoch 15/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.8860 - loss: 0.3108 - val_accuracy: 0.9028 - val_loss: 0.3391
Epoch 16/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.9104 - loss: 0.2389 - val_accuracy: 0.8536 - val_loss: 0.4585
Epoch 17/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 458ms/step - accuracy: 0.9194 - loss: 0.2460 - val_accuracy: 0.8969 - val_loss: 0.2552
Epoch 18/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 457ms/step - accuracy: 0.9379 - loss: 0.1938 - val_accuracy: 0.9371 - val_loss: 0.1968
Epoch 19/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 456ms/step - accuracy: 0.9471 - loss: 0.1733 - val_accuracy: 0.9342 - val_loss: 0.2159
Epoch 20/20
64/64 ━━━━━━━━━━━━━━━━━━━━ 30s 455ms/step - accuracy: 0.9604 - loss: 0.1334 - val_accuracy: 0.9077 - val_loss: 0.3010
Saving model.
Plotting Model Accuracy.
Saved Graph #1
Plotting Model Loss
Saved Graph #2.
Loading model.
Running inference on new data.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step
[[9.648401  0.3246979 2.9266872]]
indexOfMax: 0
Done

