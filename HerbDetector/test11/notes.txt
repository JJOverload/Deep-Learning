Quadruple image set, with proper rotations this time, which will also go through augmentation.
batch_size = 128

-----------------------

def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    

    # Entry block
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.Conv2D(64, (3, 3), strides=1, activation='relu')(x)
    x = layers.AveragePooling2D((2, 2))(x)
    x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)
    #x = layers.AveragePooling2D((2, 2))(x)
    #x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)


    if num_classes == 2:
        units = 1
    else:
        units = num_classes

    x = layers.Flatten()(x)
    x = layers.Dropout(0.25)(x)
    # We specify activation=None so as to return logits
    outputs = layers.Dense(units, activation=None)(x)
    return keras.Model(inputs, outputs)

print("Building a model.")
model = make_model(input_shape=image_size+(3,), num_classes=3)

--------------------------------------------------------


2024-01-24 15:05:38.324936: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-24 15:05:38.344611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Finished importing.
Filter out corrupted images.
Deleted 0 images
Generating a Dataset.
Found 5090 files belonging to 3 classes.
Using 4072 files for training.
Using 1018 files for validation.
Applying `data_augmentation` to the training images.
Prefetching samples in GPU memory helps maximize GPU utilization.
Building a model.
Saved Model Layout Map.
Training the model.
Epoch 1/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.3759 - loss: 3.2919 - val_accuracy: 0.5265 - val_loss: 1.0203
Epoch 2/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 53s 2s/step - accuracy: 0.5241 - loss: 0.9769 - val_accuracy: 0.6248 - val_loss: 0.8644
Epoch 3/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.6389 - loss: 0.8319 - val_accuracy: 0.6640 - val_loss: 0.8343
Epoch 4/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.6686 - loss: 0.7349 - val_accuracy: 0.6081 - val_loss: 0.9890
Epoch 5/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7083 - loss: 0.6779 - val_accuracy: 0.6965 - val_loss: 0.7750
Epoch 6/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7226 - loss: 0.6340 - val_accuracy: 0.6709 - val_loss: 0.8377
Epoch 7/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7717 - loss: 0.5703 - val_accuracy: 0.7446 - val_loss: 0.7207
Epoch 8/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8188 - loss: 0.5157 - val_accuracy: 0.7485 - val_loss: 0.6739
Epoch 9/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8105 - loss: 0.4927 - val_accuracy: 0.7259 - val_loss: 0.6873
Epoch 10/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8327 - loss: 0.4572 - val_accuracy: 0.7308 - val_loss: 0.7002
Epoch 11/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8497 - loss: 0.4252 - val_accuracy: 0.7525 - val_loss: 0.6710
Epoch 12/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8807 - loss: 0.3691 - val_accuracy: 0.7682 - val_loss: 0.6475
Epoch 13/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8882 - loss: 0.3317 - val_accuracy: 0.7849 - val_loss: 0.6154
Epoch 14/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8750 - loss: 0.3610 - val_accuracy: 0.7220 - val_loss: 0.8301
Epoch 15/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8979 - loss: 0.3054 - val_accuracy: 0.8811 - val_loss: 0.3243
Epoch 16/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.8914 - loss: 0.3134 - val_accuracy: 0.7839 - val_loss: 0.5836
Epoch 17/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.9147 - loss: 0.2644 - val_accuracy: 0.8536 - val_loss: 0.4241
Epoch 18/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.9246 - loss: 0.2499 - val_accuracy: 0.7839 - val_loss: 0.6078
Epoch 19/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 53s 2s/step - accuracy: 0.9281 - loss: 0.2387 - val_accuracy: 0.8527 - val_loss: 0.3651
Epoch 20/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.9356 - loss: 0.2228 - val_accuracy: 0.8644 - val_loss: 0.3380
Epoch 21/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.9299 - loss: 0.2173 - val_accuracy: 0.8134 - val_loss: 0.5404
Epoch 22/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 53s 2s/step - accuracy: 0.9408 - loss: 0.1978 - val_accuracy: 0.8251 - val_loss: 0.5160
Epoch 23/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 53s 2s/step - accuracy: 0.9539 - loss: 0.1726 - val_accuracy: 0.8487 - val_loss: 0.4204
Epoch 24/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 53s 2s/step - accuracy: 0.9495 - loss: 0.1676 - val_accuracy: 0.9175 - val_loss: 0.2246
Epoch 25/25
32/32 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.9412 - loss: 0.1875 - val_accuracy: 0.8929 - val_loss: 0.3260
Saving model.
Plotting Model Accuracy.
Saved Graph #1
Plotting Model Loss
Saved Graph #2.
Loading model.
Running inference on new data.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step
[[-1.5633032 -1.9920549 -9.651357 ]]
indexOfMax: 0
Done


