Doubled image set, which will go through augmentation.
Restored batch size.

-----------------------

def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    

    # Entry block
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.Conv2D(64, (3, 3), strides=1, activation='relu')(x)
    x = layers.AveragePooling2D((2, 2))(x)
    x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)
    #x = layers.AveragePooling2D((2, 2))(x)
    #x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)


    if num_classes == 2:
        units = 1
    else:
        units = num_classes

    x = layers.Flatten()(x)
    x = layers.Dropout(0.25)(x)
    # We specify activation=None so as to return logits
    outputs = layers.Dense(units, activation=None)(x)
    return keras.Model(inputs, outputs)

print("Building a model.")
model = make_model(input_shape=image_size+(3,), num_classes=3)

--------------------------------------------------------



2024-01-23 15:09:06.666580: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-23 15:09:06.686106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Finished importing.
Filter out corrupted images.
Deleted 0 images
Generating a Dataset.
Found 1858 files belonging to 3 classes.
Using 1487 files for training.
Using 371 files for validation.
Applying `data_augmentation` to the training images.
Prefetching samples in GPU memory helps maximize GPU utilization.
Building a model.
Saved Model Layout Map.
Training the model.
Epoch 1/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.3193 - loss: 5.7710 - val_accuracy: 0.3477 - val_loss: 1.5589
Epoch 2/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.3735 - loss: 1.3907 - val_accuracy: 0.4232 - val_loss: 1.0469
Epoch 3/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.5176 - loss: 1.0250 - val_accuracy: 0.7008 - val_loss: 0.8718
Epoch 4/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.6137 - loss: 0.8674 - val_accuracy: 0.6900 - val_loss: 0.7819
Epoch 5/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 21s 2s/step - accuracy: 0.6950 - loss: 0.7357 - val_accuracy: 0.7709 - val_loss: 0.5965
Epoch 6/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.7605 - loss: 0.6361 - val_accuracy: 0.7817 - val_loss: 0.5219
Epoch 7/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.7555 - loss: 0.5814 - val_accuracy: 0.8518 - val_loss: 0.4424
Epoch 8/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.7860 - loss: 0.5458 - val_accuracy: 0.8868 - val_loss: 0.3805
Epoch 9/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.8401 - loss: 0.4400 - val_accuracy: 0.8221 - val_loss: 0.5550
Epoch 10/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.8946 - loss: 0.3562 - val_accuracy: 0.8356 - val_loss: 0.4590
Epoch 11/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9354 - loss: 0.2735 - val_accuracy: 0.8706 - val_loss: 0.3564
Epoch 12/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9406 - loss: 0.2339 - val_accuracy: 0.8976 - val_loss: 0.2608
Epoch 13/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9430 - loss: 0.2090 - val_accuracy: 0.9407 - val_loss: 0.2293
Epoch 14/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9665 - loss: 0.1712 - val_accuracy: 0.8922 - val_loss: 0.3553
Epoch 15/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9666 - loss: 0.1660 - val_accuracy: 0.9326 - val_loss: 0.2916
Epoch 16/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9687 - loss: 0.1467 - val_accuracy: 0.9272 - val_loss: 0.3545
Epoch 17/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9827 - loss: 0.1108 - val_accuracy: 0.9272 - val_loss: 0.2529
Epoch 18/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9749 - loss: 0.1117 - val_accuracy: 0.9407 - val_loss: 0.2447
Epoch 19/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9796 - loss: 0.1009 - val_accuracy: 0.9488 - val_loss: 0.1784
Epoch 20/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9798 - loss: 0.0927 - val_accuracy: 0.9111 - val_loss: 0.3086
Epoch 21/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9874 - loss: 0.0715 - val_accuracy: 0.9137 - val_loss: 0.3468
Epoch 22/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9917 - loss: 0.0663 - val_accuracy: 0.9191 - val_loss: 0.3089
Epoch 23/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9888 - loss: 0.0657 - val_accuracy: 0.8140 - val_loss: 0.5406
Epoch 24/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9817 - loss: 0.0959 - val_accuracy: 0.8760 - val_loss: 0.3900
Epoch 25/25
12/12 ━━━━━━━━━━━━━━━━━━━━ 20s 2s/step - accuracy: 0.9832 - loss: 0.0625 - val_accuracy: 0.9515 - val_loss: 0.1205
Saving model.
Plotting Model Accuracy.
Saved Graph #1
Plotting Model Loss
Saved Graph #2.
Loading model.
Running inference on new data.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step
[[-0.77240497 -4.8540025  -4.0365267 ]]
indexOfMax: 0
Done


