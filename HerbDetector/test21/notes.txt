Quadruple image set, with proper rotations this time, which will also go through augmentation.

1x batch normalization, and then another 1x batch normalization after pooling.
batch_size = 32
epoch 30


-----------------------

def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    

    # Entry block
    x = layers.Rescaling(1.0 / 255)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(64, (6, 6), strides=1, activation='relu')(x)
    x = layers.AveragePooling2D((3, 3))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(128, (6, 6), strides=1, activation='relu')(x)
    
    
    
    #x = layers.AveragePooling2D((2, 2))(x)
    #x = layers.Conv2D(128, (3, 3), strides=1, activation='relu')(x)


    if num_classes == 2:
        units = 1
    else:
        units = num_classes

    x = layers.Flatten()(x)
    x = layers.Dropout(0.25)(x)
    # We specify activation=None so as to return logits
    outputs = layers.Dense(units, activation=None)(x)
    return keras.Model(inputs, outputs)

print("Building a model.")
model = make_model(input_shape=image_size+(3,), num_classes=3)

--------------------------------------------------------

2024-01-24 21:16:33.354308: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-01-24 21:16:33.373087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Finished importing.
Filter out corrupted images.
Deleted 0 images
Generating a Dataset.
Found 5090 files belonging to 3 classes.
Using 4072 files for training.
Using 1018 files for validation.
Applying `data_augmentation` to the training images.
Prefetching samples in GPU memory helps maximize GPU utilization.
Building a model.
Saved Model Layout Map.
Training the model.
Epoch 1/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 68s 526ms/step - accuracy: 0.4593 - loss: 5.6688 - val_accuracy: 0.5737 - val_loss: 0.9088
Epoch 2/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 71s 548ms/step - accuracy: 0.6350 - loss: 1.0764 - val_accuracy: 0.5236 - val_loss: 1.4388
Epoch 3/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 71s 548ms/step - accuracy: 0.6150 - loss: 1.4276 - val_accuracy: 0.6473 - val_loss: 1.0133
Epoch 4/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 544ms/step - accuracy: 0.6202 - loss: 1.8498 - val_accuracy: 0.6464 - val_loss: 1.3663
Epoch 5/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.6735 - loss: 1.4121 - val_accuracy: 0.7800 - val_loss: 0.7881
Epoch 6/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.7134 - loss: 1.1437 - val_accuracy: 0.6847 - val_loss: 1.0747
Epoch 7/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 537ms/step - accuracy: 0.7467 - loss: 0.8006 - val_accuracy: 0.7859 - val_loss: 0.5416
Epoch 8/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 538ms/step - accuracy: 0.7875 - loss: 0.6417 - val_accuracy: 0.8134 - val_loss: 0.4932
Epoch 9/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 544ms/step - accuracy: 0.8352 - loss: 0.4628 - val_accuracy: 0.7790 - val_loss: 0.6593
Epoch 10/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 542ms/step - accuracy: 0.8685 - loss: 0.3627 - val_accuracy: 0.8134 - val_loss: 0.5616
Epoch 11/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.8848 - loss: 0.3188 - val_accuracy: 0.7849 - val_loss: 0.5596
Epoch 12/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 541ms/step - accuracy: 0.8892 - loss: 0.3061 - val_accuracy: 0.8605 - val_loss: 0.3601
Epoch 13/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.8820 - loss: 0.3333 - val_accuracy: 0.8379 - val_loss: 0.4556
Epoch 14/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9196 - loss: 0.2372 - val_accuracy: 0.8870 - val_loss: 0.3407
Epoch 15/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 541ms/step - accuracy: 0.9043 - loss: 0.2632 - val_accuracy: 0.9067 - val_loss: 0.2873
Epoch 16/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.9075 - loss: 0.3151 - val_accuracy: 0.9165 - val_loss: 0.2795
Epoch 17/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 543ms/step - accuracy: 0.9242 - loss: 0.2083 - val_accuracy: 0.9519 - val_loss: 0.2027
Epoch 18/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9325 - loss: 0.2092 - val_accuracy: 0.9558 - val_loss: 0.1620
Epoch 19/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.9426 - loss: 0.1586 - val_accuracy: 0.9538 - val_loss: 0.1883
Epoch 20/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 541ms/step - accuracy: 0.9494 - loss: 0.1574 - val_accuracy: 0.8713 - val_loss: 0.4079
Epoch 21/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9062 - loss: 0.3001 - val_accuracy: 0.9165 - val_loss: 0.3210
Epoch 22/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 541ms/step - accuracy: 0.9381 - loss: 0.2064 - val_accuracy: 0.9489 - val_loss: 0.1779
Epoch 23/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 543ms/step - accuracy: 0.9297 - loss: 0.2120 - val_accuracy: 0.8880 - val_loss: 0.4655
Epoch 24/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9359 - loss: 0.2031 - val_accuracy: 0.9479 - val_loss: 0.2229
Epoch 25/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 541ms/step - accuracy: 0.9374 - loss: 0.1924 - val_accuracy: 0.9037 - val_loss: 0.4229
Epoch 26/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9111 - loss: 0.2975 - val_accuracy: 0.9283 - val_loss: 0.2895
Epoch 27/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.9452 - loss: 0.1641 - val_accuracy: 0.9322 - val_loss: 0.2709
Epoch 28/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 69s 539ms/step - accuracy: 0.9457 - loss: 0.1693 - val_accuracy: 0.9401 - val_loss: 0.2182
Epoch 29/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9507 - loss: 0.1568 - val_accuracy: 0.9352 - val_loss: 0.2931
Epoch 30/30
128/128 ━━━━━━━━━━━━━━━━━━━━ 70s 540ms/step - accuracy: 0.9356 - loss: 0.2621 - val_accuracy: 0.9686 - val_loss: 0.1594
Saving model.
Plotting Model Accuracy.
Saved Graph #1
Plotting Model Loss
Saved Graph #2.
Loading model.
Running inference on new data.
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step
[[ 6.6611557 -0.8749549 -2.564809 ]]
indexOfMax: 0
Done

